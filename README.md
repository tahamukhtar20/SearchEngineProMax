A web crawler based distributed search engine utilizing Bloom Filters, Apache Spark, Solr, and BERT-based page ranking for efficient and accurate information retrieval.

## Getting Started

To run this on your local machine make sure you have python and (optional but preferably) conda installed on your device.

1. Install packages using conda:

   Run the following command in the project directory `conda env create -f environment.yml`

2. Install packages using pip:

   Run the following command in the project directory `pip install -r requirements.txt`

3. Run main.py to start the crawler.
